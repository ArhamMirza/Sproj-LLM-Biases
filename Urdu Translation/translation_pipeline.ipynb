{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11650240,"sourceType":"datasetVersion","datasetId":7311086}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Dependencies**","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers.git sentencepiece","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Facebook m4t Setup**","metadata":{}},{"cell_type":"code","source":"# import torch\n# from transformers import AutoProcessor, SeamlessM4Tv2Model\n\n# processor = AutoProcessor.from_pretrained(\"facebook/seamless-m4t-v2-large\")\n# model = SeamlessM4Tv2Model.from_pretrained(\"facebook/seamless-m4t-v2-large\")\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #snd (sindhi) and pbt (pashto)\n# english_text = \"On that day, two people came into the lawyer's office, one with a new briefcase and the other maneuvering his wheelchair through the door.\"\n\n# text_inputs = processor(text=english_text, src_lang=\"eng\", return_tensors=\"pt\").to(device)\n# output_tokens = model.generate(**text_inputs, tgt_lang=\"urd\", generate_speech=False)\n# translated_text = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n# print(\"Translated Text:\", translated_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport torch\nfrom transformers import AutoProcessor, SeamlessM4Tv2Model\nfrom tqdm import tqdm\n\nLoad model and processor\nprocessor = AutoProcessor.from_pretrained(\"facebook/seamless-m4t-v2-large\")\nmodel = SeamlessM4Tv2Model.from_pretrained(\"facebook/seamless-m4t-v2-large\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ninput_path = \"/kaggle/input/sproj-appearance/Appearance.jsonl\"\noutput_path = \"/kaggle/working/Appearance_translated.jsonl\"\n\ndef translate_text(text, src_lang=\"eng\", tgt_lang=\"urd\"):\n    \"\"\"Translate a single text string.\"\"\"\n    try:\n        inputs = processor(text=text, src_lang=src_lang, return_tensors=\"pt\")\n        inputs = {k: v.to(device) for k, v in inputs.items()}\n        output = model.generate(**inputs, tgt_lang=tgt_lang, generate_speech=False)\n        \n        try:\n            if hasattr(output[0], 'cpu'):\n                tokens = output[0].cpu()\n                if hasattr(processor, 'batch_decode'):\n                    return processor.batch_decode(tokens, skip_special_tokens=True)[0]\n                else:\n                    decoded = \"\"\n                    for token in tokens:\n                        decoded += processor.tokenizer.convert_ids_to_tokens(token.item())\n                    return decoded\n            elif isinstance(output[0], list):\n                return \" \".join(str(x) for x in output[0])\n            else:\n                return str(output[0])\n        except Exception as inner_e:\n            print(f\"Decoding error: {inner_e}\")\n            return text\n            \n    except Exception as e:\n        print(f\"Error translating '{text[:30]}...': {e}\")\n        return text  \n\ndef process_jsonl_file():\n    \"\"\"Process the JSONL file line by line.\"\"\"\n    fields_to_translate = [\"context\", \"question\"]\n    answer_fields = [\"ans0\", \"ans1\", \"ans2\"]\n    \n    with open(input_path, 'r', encoding='utf-8') as infile, open(output_path, 'w', encoding='utf-8') as outfile:\n        for line_num, line in enumerate(tqdm(infile, desc=\"Processing\")):\n            if not line.strip():\n                continue\n                \n            try:\n                data = json.loads(line)\n                \n                for field in fields_to_translate:\n                    if field in data and data[field]:\n                        data[field] = translate_text(data[field])\n                \n                for ans_field in answer_fields:\n                    if \"answer_info\" in data and ans_field in data[\"answer_info\"] and data[\"answer_info\"][ans_field]:\n                        translated_options = []\n                        for ans_text in data[\"answer_info\"][ans_field]:\n                            translated = translate_text(ans_text)\n                            translated_options.append(translated)\n                        data[\"answer_info\"][ans_field] = translated_options\n                \n                for field in answer_fields:\n                    if field in data and data[field]:\n                        data[field] = translate_text(data[field])\n                \n                outfile.write(json.dumps(data, ensure_ascii=False) + '\\n')\n                \n            except json.JSONDecodeError as e:\n                print(f\"Error decoding line {line_num}: {e}\")\n                continue\n            except Exception as e:\n                print(f\"Error processing line {line_num}: {e}\")\n                continue\n\n\nif __name__ == \"__main__\":\n    test_text = \"A fair-skinned Pakistani and a dark-skinned Pakistani applying for a modeling job.\"\n    print(\"Testing translation...\")\n    translated = translate_text(test_text)\n    print(f\"Original: {test_text}\")\n    print(f\"Translated: {translated}\")\n    print(\"Starting main processing...\")\n    \n    process_jsonl_file()\n    print(f\"âœ… Translation complete. Output file saved to: {output_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}